{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQle8GogbNuut/XUw12As8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsingh050/1-D_Cochlear/blob/main/CNN_model_for_BCI_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My code was adapted from Dr. Xiang Zhang (xiang_zhang@hms.harvard.edu), Prof. Lina Yao (lina.yao@unsw.edu.au)\n",
        "Citations for some of their materials can be provided here\n",
        "article{zhang2020survey,\n",
        "  title={A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers},\n",
        "  author={Zhang, Xiang and Yao, Lina and Wang, Xianzhi and Monaghan, Jessica JM and Mcalpine, David and Zhang, Yu},\n",
        "  journal={Journal of Neural Engineering},\n",
        "  year={2020},\n",
        "  publisher={IOP Publishing}\n",
        "}\n",
        "\n",
        "@book{zhang2021deep,\n",
        "  title={Deep Learning for EEG-based Brain-Computer Interface: Representations, Algorithms and Applications},\n",
        "  author={Zhang, Xiang and Yao, Lina},\n",
        "  year={2021},\n",
        "  publisher={World Scientific Publishing}\n",
        "}"
      ],
      "metadata": {
        "id": "PkWHkqUJMK6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com//xiangzhang1015/Deep-Learning-for-BCI.git\n",
        "%cd Deep-Learning-for-BCI/dataset\n",
        "!ls\n",
        "\n",
        "!mkdir -p unzipped_data\n",
        "!unzip \"*.zip\" -d /content/Deep-Learning-for-BCI/dataset/unzipped_data\n",
        "\n",
        "\n",
        "!ls /content/Deep-Learning-for-BCI/dataset/unzipped_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct68es_kMYgW",
        "outputId": "9bcefb2f-5199-48e9-b850-552715d2d541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-Learning-for-BCI'...\n",
            "remote: Enumerating objects: 448, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 448 (delta 0), reused 1 (delta 0), pack-reused 445 (from 1)\u001b[K\n",
            "Receiving objects: 100% (448/448), 2.14 GiB | 24.36 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Updating files: 100% (137/137), done.\n",
            "/content/Deep-Learning-for-BCI/dataset\n",
            "100.zip  10.zip  1.zip\t 29.zip  38.zip  47.zip  56.zip  65.zip  74.zip  83.zip  92.zip\n",
            "101.zip  11.zip  20.zip  2.zip\t 39.zip  48.zip  57.zip  66.zip  75.zip  84.zip  93.zip\n",
            "102.zip  12.zip  21.zip  30.zip  3.zip\t 49.zip  58.zip  67.zip  76.zip  85.zip  94.zip\n",
            "103.zip  13.zip  22.zip  31.zip  40.zip  4.zip\t 59.zip  68.zip  77.zip  86.zip  95.zip\n",
            "104.zip  14.zip  23.zip  32.zip  41.zip  50.zip  5.zip\t 69.zip  78.zip  87.zip  96.zip\n",
            "105.zip  15.zip  24.zip  33.zip  42.zip  51.zip  60.zip  6.zip\t 79.zip  88.zip  97.zip\n",
            "106.zip  16.zip  25.zip  34.zip  43.zip  52.zip  61.zip  70.zip  7.zip\t 89.zip  98.zip\n",
            "107.zip  17.zip  26.zip  35.zip  44.zip  53.zip  62.zip  71.zip  80.zip  8.zip\t 99.zip\n",
            "108.zip  18.zip  27.zip  36.zip  45.zip  54.zip  63.zip  72.zip  81.zip  90.zip  9.zip\n",
            "109.zip  19.zip  28.zip  37.zip  46.zip  55.zip  64.zip  73.zip  82.zip  91.zip  notes\n",
            "Archive:  79.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/79.npy  \n",
            "\n",
            "Archive:  49.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/49.npy  \n",
            "\n",
            "Archive:  2.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/2.npy  \n",
            "\n",
            "Archive:  85.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/85.npy  \n",
            "\n",
            "Archive:  106.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/106.npy  \n",
            "\n",
            "Archive:  100.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/100.npy  \n",
            "\n",
            "Archive:  69.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/69.npy  \n",
            "\n",
            "Archive:  50.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/50.npy  \n",
            "\n",
            "Archive:  8.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/8.npy  \n",
            "\n",
            "Archive:  21.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/21.npy  \n",
            "\n",
            "Archive:  90.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/90.npy  \n",
            "\n",
            "Archive:  33.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/33.npy  \n",
            "\n",
            "Archive:  23.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/23.npy  \n",
            "\n",
            "Archive:  19.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/19.npy  \n",
            "\n",
            "Archive:  86.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/86.npy  \n",
            "\n",
            "Archive:  9.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/9.npy  \n",
            "\n",
            "Archive:  12.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/12.npy  \n",
            "\n",
            "Archive:  46.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/46.npy  \n",
            "\n",
            "Archive:  93.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/93.npy  \n",
            "\n",
            "Archive:  32.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/32.npy  \n",
            "\n",
            "Archive:  71.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/71.npy  \n",
            "\n",
            "Archive:  54.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/54.npy  \n",
            "\n",
            "Archive:  35.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/35.npy  \n",
            "\n",
            "Archive:  91.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/91.npy  \n",
            "\n",
            "Archive:  61.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/61.npy  \n",
            "\n",
            "Archive:  52.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/52.npy  \n",
            "\n",
            "Archive:  59.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/59.npy  \n",
            "\n",
            "Archive:  48.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/48.npy  \n",
            "\n",
            "Archive:  98.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/98.npy  \n",
            "\n",
            "Archive:  104.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/104.npy  \n",
            "\n",
            "Archive:  1.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/1.npy  \n",
            "\n",
            "Archive:  47.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/47.npy  \n",
            "\n",
            "Archive:  108.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/108.npy  \n",
            "\n",
            "Archive:  73.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/73.npy  \n",
            "\n",
            "Archive:  25.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/25.npy  \n",
            "\n",
            "Archive:  99.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/99.npy  \n",
            "\n",
            "Archive:  14.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/14.npy  \n",
            "\n",
            "Archive:  53.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/53.npy  \n",
            "\n",
            "Archive:  36.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/36.npy  \n",
            "\n",
            "Archive:  70.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/70.npy  \n",
            "\n",
            "Archive:  58.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/58.npy  \n",
            "\n",
            "Archive:  13.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/13.npy  \n",
            "\n",
            "Archive:  39.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/39.npy  \n",
            "\n",
            "Archive:  76.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/76.npy  \n",
            "\n",
            "Archive:  75.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/75.npy  \n",
            "\n",
            "Archive:  97.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/97.npy  \n",
            "\n",
            "Archive:  74.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/74.npy  \n",
            "\n",
            "Archive:  77.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/77.npy  \n",
            "\n",
            "Archive:  84.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/84.npy  \n",
            "\n",
            "Archive:  87.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/87.npy  \n",
            "\n",
            "Archive:  30.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/30.npy  \n",
            "\n",
            "Archive:  20.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/20.npy  \n",
            "\n",
            "Archive:  68.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/68.npy  \n",
            "\n",
            "Archive:  44.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/44.npy  \n",
            "\n",
            "Archive:  101.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/101.npy  \n",
            "\n",
            "Archive:  94.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/94.npy  \n",
            "\n",
            "Archive:  60.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/60.npy  \n",
            "\n",
            "Archive:  15.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/15.npy  \n",
            "\n",
            "Archive:  62.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/62.npy  \n",
            "\n",
            "Archive:  16.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/16.npy  \n",
            "\n",
            "Archive:  109.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/109.npy  \n",
            "\n",
            "Archive:  11.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/11.npy  \n",
            "\n",
            "Archive:  5.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/5.npy  \n",
            "\n",
            "Archive:  34.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/34.npy  \n",
            "\n",
            "Archive:  63.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/63.npy  \n",
            "\n",
            "Archive:  78.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/78.npy  \n",
            "\n",
            "Archive:  42.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/42.npy  \n",
            "\n",
            "Archive:  57.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/57.npy  \n",
            "\n",
            "Archive:  107.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/107.npy  \n",
            "\n",
            "Archive:  95.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/95.npy  \n",
            "\n",
            "Archive:  102.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/102.npy  \n",
            "\n",
            "Archive:  82.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/82.npy  \n",
            "\n",
            "Archive:  40.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/40.npy  \n",
            "\n",
            "Archive:  103.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/103.npy  \n",
            "\n",
            "Archive:  18.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/18.npy  \n",
            "\n",
            "Archive:  6.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/6.npy  \n",
            "\n",
            "Archive:  38.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/38.npy  \n",
            "\n",
            "Archive:  51.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/51.npy  \n",
            "\n",
            "Archive:  64.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/64.npy  \n",
            "\n",
            "Archive:  105.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/105.npy  \n",
            "\n",
            "Archive:  28.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/28.npy  \n",
            "\n",
            "Archive:  89.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/89.npy  \n",
            "\n",
            "Archive:  72.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/72.npy  \n",
            "\n",
            "Archive:  66.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/66.npy  \n",
            "\n",
            "Archive:  29.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/29.npy  \n",
            "\n",
            "Archive:  31.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/31.npy  \n",
            "\n",
            "Archive:  24.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/24.npy  \n",
            "\n",
            "Archive:  65.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/65.npy  \n",
            "\n",
            "Archive:  22.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/22.npy  \n",
            "\n",
            "Archive:  3.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/3.npy  \n",
            "\n",
            "Archive:  56.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/56.npy  \n",
            "\n",
            "Archive:  45.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/45.npy  \n",
            "\n",
            "Archive:  80.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/80.npy  \n",
            "\n",
            "Archive:  41.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/41.npy  \n",
            "\n",
            "Archive:  7.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/7.npy  \n",
            "\n",
            "Archive:  88.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/88.npy  \n",
            "\n",
            "Archive:  55.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/55.npy  \n",
            "\n",
            "Archive:  17.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/17.npy  \n",
            "\n",
            "Archive:  27.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/27.npy  \n",
            "\n",
            "Archive:  96.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/96.npy  \n",
            "\n",
            "Archive:  92.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/92.npy  \n",
            "\n",
            "Archive:  26.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/26.npy  \n",
            "\n",
            "Archive:  37.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/37.npy  \n",
            "\n",
            "Archive:  67.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/67.npy  \n",
            "\n",
            "Archive:  43.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/43.npy  \n",
            "\n",
            "Archive:  10.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/10.npy  \n",
            "\n",
            "Archive:  81.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/81.npy  \n",
            "\n",
            "Archive:  83.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/83.npy  \n",
            "\n",
            "Archive:  4.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/4.npy  \n",
            "\n",
            "109 archives were successfully processed.\n",
            "100.npy  10.npy  1.npy\t 29.npy  38.npy  47.npy  56.npy  65.npy  74.npy  83.npy  92.npy\n",
            "101.npy  11.npy  20.npy  2.npy\t 39.npy  48.npy  57.npy  66.npy  75.npy  84.npy  93.npy\n",
            "102.npy  12.npy  21.npy  30.npy  3.npy\t 49.npy  58.npy  67.npy  76.npy  85.npy  94.npy\n",
            "103.npy  13.npy  22.npy  31.npy  40.npy  4.npy\t 59.npy  68.npy  77.npy  86.npy  95.npy\n",
            "104.npy  14.npy  23.npy  32.npy  41.npy  50.npy  5.npy\t 69.npy  78.npy  87.npy  96.npy\n",
            "105.npy  15.npy  24.npy  33.npy  42.npy  51.npy  60.npy  6.npy\t 79.npy  88.npy  97.npy\n",
            "106.npy  16.npy  25.npy  34.npy  43.npy  52.npy  61.npy  70.npy  7.npy\t 89.npy  98.npy\n",
            "107.npy  17.npy  26.npy  35.npy  44.npy  53.npy  62.npy  71.npy  80.npy  8.npy\t 99.npy\n",
            "108.npy  18.npy  27.npy  36.npy  45.npy  54.npy  63.npy  72.npy  81.npy  90.npy  9.npy\n",
            "109.npy  19.npy  28.npy  37.npy  46.npy  55.npy  64.npy  73.npy  82.npy  91.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial for CNN. My goal was to just run a tutorial and I tried data augmentation and changing the layers but since the OG code was SO well documented I kind of used it as a tutorial and learned more about it and then got to  and run step by step, then I got to debug, then (time-depending) I will make tweaks to the code. Here I changed the act function/layers in the CNN. The goal of this was just to be an exploration and I did a lot of research into datasets. I wanted to use the BCI dataset I talked about in my lit review but not enough time.\n",
        "\n",
        "Adapted from: Dr. Xiang Zhang (xiang_zhang@hms.harvard.edu), Prof. Lina Yao (lina.yao@unsw.edu.au) at https://github.com/xiangzhang1015/Deep-Learning-for-BCI."
      ],
      "metadata": {
        "id": "enJZrKDTNYkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#what the OG team did to load their data\n",
        "#  dataset_1 = np.load('1.npy')\n",
        "# print('dataset_1 shape:', dataset_1.shape)\n"
      ],
      "metadata": {
        "id": "aW7bkjWhP9uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries and load the dataset from github via cloning (I actually have never done this!)\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report\n",
        "import os\n",
        "\n",
        "# Path to the directory containing .npy files\n",
        "data_path = '/content/Deep-Learning-for-BCI/dataset/unzipped_data'\n",
        "\n",
        "# List all .npy files in the directory\n",
        "file_list = [file for file in os.listdir(data_path) if file.endswith('.npy')]\n",
        "\n",
        "# Load all .npy files into a list\n",
        "datasets = []\n",
        "for file_name in file_list:\n",
        "    file_path = os.path.join(data_path, file_name)\n",
        "    data = np.load(file_path)\n",
        "    datasets.append(data)\n",
        "    print(f'{file_name} shape: {data.shape}')\n",
        "\n",
        "print(f\"Total number of files loaded: {len(datasets)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBMx06aNaof",
        "outputId": "2f7c1034-fd36-47d7-b4f8-156574556571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.npy shape: (259520, 65)\n",
            "50.npy shape: (255680, 65)\n",
            "11.npy shape: (255680, 65)\n",
            "30.npy shape: (257600, 65)\n",
            "85.npy shape: (255680, 65)\n",
            "39.npy shape: (255680, 65)\n",
            "69.npy shape: (255520, 65)\n",
            "96.npy shape: (259520, 65)\n",
            "67.npy shape: (255680, 65)\n",
            "78.npy shape: (255680, 65)\n",
            "102.npy shape: (255840, 65)\n",
            "82.npy shape: (255680, 65)\n",
            "71.npy shape: (259520, 65)\n",
            "9.npy shape: (255680, 65)\n",
            "99.npy shape: (255680, 65)\n",
            "88.npy shape: (209984, 65)\n",
            "81.npy shape: (255680, 65)\n",
            "56.npy shape: (255680, 65)\n",
            "40.npy shape: (255680, 65)\n",
            "49.npy shape: (255680, 65)\n",
            "79.npy shape: (259520, 65)\n",
            "18.npy shape: (255680, 65)\n",
            "61.npy shape: (259520, 65)\n",
            "97.npy shape: (255520, 65)\n",
            "105.npy shape: (255680, 65)\n",
            "62.npy shape: (255680, 65)\n",
            "36.npy shape: (255680, 65)\n",
            "16.npy shape: (255680, 65)\n",
            "7.npy shape: (259520, 65)\n",
            "46.npy shape: (259520, 65)\n",
            "33.npy shape: (255680, 65)\n",
            "15.npy shape: (255680, 65)\n",
            "77.npy shape: (255680, 65)\n",
            "1.npy shape: (259520, 65)\n",
            "60.npy shape: (255680, 65)\n",
            "3.npy shape: (259520, 65)\n",
            "26.npy shape: (255680, 65)\n",
            "24.npy shape: (255680, 65)\n",
            "21.npy shape: (259520, 65)\n",
            "93.npy shape: (255680, 65)\n",
            "5.npy shape: (255680, 65)\n",
            "98.npy shape: (255680, 65)\n",
            "87.npy shape: (255680, 65)\n",
            "20.npy shape: (255680, 65)\n",
            "92.npy shape: (209984, 65)\n",
            "54.npy shape: (255680, 65)\n",
            "12.npy shape: (255680, 65)\n",
            "45.npy shape: (255680, 65)\n",
            "91.npy shape: (255680, 65)\n",
            "74.npy shape: (255840, 65)\n",
            "64.npy shape: (256160, 65)\n",
            "90.npy shape: (255680, 65)\n",
            "76.npy shape: (255680, 65)\n",
            "68.npy shape: (255680, 65)\n",
            "53.npy shape: (255680, 65)\n",
            "31.npy shape: (255680, 65)\n",
            "107.npy shape: (259520, 65)\n",
            "10.npy shape: (255680, 65)\n",
            "101.npy shape: (259520, 65)\n",
            "70.npy shape: (255680, 65)\n",
            "80.npy shape: (255680, 65)\n",
            "38.npy shape: (255680, 65)\n",
            "48.npy shape: (255680, 65)\n",
            "109.npy shape: (255520, 65)\n",
            "44.npy shape: (255680, 65)\n",
            "32.npy shape: (259520, 65)\n",
            "13.npy shape: (255680, 65)\n",
            "19.npy shape: (255680, 65)\n",
            "51.npy shape: (256480, 65)\n",
            "58.npy shape: (255680, 65)\n",
            "83.npy shape: (259520, 65)\n",
            "63.npy shape: (255680, 65)\n",
            "47.npy shape: (255680, 65)\n",
            "2.npy shape: (255680, 65)\n",
            "42.npy shape: (255680, 65)\n",
            "41.npy shape: (256320, 65)\n",
            "23.npy shape: (255680, 65)\n",
            "6.npy shape: (255680, 65)\n",
            "22.npy shape: (259520, 65)\n",
            "73.npy shape: (255680, 65)\n",
            "14.npy shape: (255520, 65)\n",
            "27.npy shape: (255680, 65)\n",
            "86.npy shape: (259520, 65)\n",
            "108.npy shape: (255680, 65)\n",
            "17.npy shape: (255680, 65)\n",
            "84.npy shape: (255680, 65)\n",
            "59.npy shape: (255680, 65)\n",
            "104.npy shape: (252960, 65)\n",
            "106.npy shape: (245440, 65)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "QVuTBIjkQepS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Custom Dataset Class to Load Multiple .npy Files\n",
        "class NPYDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        # List all .npy files in the directory\n",
        "        self.file_list = [file for file in os.listdir(data_path) if file.endswith('.npy')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load each .npy file dynamically\n",
        "        file_name = self.file_list[index]\n",
        "        file_path = os.path.join(self.data_path, file_name)\n",
        "        data = np.load(file_path)  # Load numpy array\n",
        "\n",
        "        # Convert numpy array to PyTorch tensor\n",
        "        x_data = torch.tensor(data, dtype=torch.float32)\n",
        "\n",
        "        # Dummy label (replace this with actual labels if available)\n",
        "        y_label = torch.tensor(index % 2, dtype=torch.long)  # Example: Class 0 or 1\n",
        "\n",
        "        return x_data, y_label\n",
        "\n",
        "# Define a custom collate function to pad sequences\n",
        "def collate_fn(batch):\n",
        "    # Separate inputs and labels\n",
        "    x_batch, y_batch = zip(*batch)\n",
        "\n",
        "    # Pad the input sequences\n",
        "    x_batch_padded = pad_sequence(x_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Stack the labels\n",
        "    y_batch = torch.stack(y_batch, dim=0)\n",
        "\n",
        "    return x_batch_padded, y_batch\n",
        "\n",
        "# Path where your .npy files are stored\n",
        "data_path = '/content/Deep-Learning-for-BCI/dataset/unzipped_data'\n",
        "\n",
        "# Create an instance of the custom Dataset\n",
        "dataset = NPYDataset(data_path)\n",
        "\n",
        "# Use DataLoader to batch the data for training or testing\n",
        "# Use the custom collate_fn\n",
        "data_loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Iterate through the DataLoader to load batches of data\n",
        "for x_batch, y_batch in data_loader:\n",
        "    print(\"Batch X shape:\", x_batch.shape)  # Shape of input data\n",
        "    print(\"Batch Y shape:\", y_batch.shape)  # Shape of labels\n",
        "    break  # Print the first batch and stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrBU3hpCUBi0",
        "outputId": "6744c819-997a-457d-fe41-8ef527952840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch X shape: torch.Size([16, 259520, 65])\n",
            "Batch Y shape: torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dataset_1 = np.load(os.path.join(data_path, '1.npy'))\n",
        "print('The shape of Dataset_1:', dataset_1.shape)\n",
        "dataset_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qijIUktU8nm",
        "outputId": "36989a2c-3d0c-473b-91a1-c313c74ba3c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of Dataset_1: (259520, 65)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-16, -29,   2, ..., -11,  15,   0],\n",
              "       [-56, -54, -27, ...,   1,  21,   0],\n",
              "       [-55, -55, -29, ...,  18,  35,   0],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unchanged code from the github\n"
      ],
      "metadata": {
        "id": "4EDJpBvR_1Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# # load dataset\n",
        "# dataset_1 = np.load('1.npy')\n",
        "# print('dataset_1 shape:', dataset_1.shape)\n",
        "\n",
        "# check if a GPU is available\n",
        "with_gpu = torch.cuda.is_available()\n",
        "if with_gpu:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print('We are using %s now.' %device)\n",
        "\n",
        "# remove instance with label==10 (rest)\n",
        "removed_label = [2,3,4,5,6,7,8,9,10]  #2,3,4,5,\n",
        "for ll in removed_label:\n",
        "    id = dataset_1[:, -1]!=ll\n",
        "    dataset_1 = dataset_1[id]\n",
        "\n",
        "def one_hot(y_):\n",
        "    # Function to encode output labels from number indexes\n",
        "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    y_ = [int(xx) for xx in y_]\n",
        "    n_values = np.max(y_) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
        "\n",
        "# data segmentation\n",
        "n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
        "no_feature = 64  # the number of the features\n",
        "segment_length = 16  # selected time window; 16=160*0.1\n",
        "LR = 0.005  # learning rate\n",
        "EPOCH = 101\n",
        "n_hidden = 128  # number of neurons in hidden layer\n",
        "l2 = 0.01  # the coefficient of l2-norm regularization\n",
        "\n",
        "def extract(input, n_classes, n_fea, time_window, moving):\n",
        "    xx = input[:, :n_fea]\n",
        "    yy = input[:, n_fea:n_fea + 1]\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    number = int((xx.shape[0] / moving) - 1)\n",
        "    for i in range(number):\n",
        "        ave_y = np.average(yy[int(i * moving):int(i * moving + time_window)])\n",
        "        if ave_y in range(n_classes + 1):\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(ave_y)\n",
        "        else:\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(0)\n",
        "\n",
        "    new_x = np.array(new_x)\n",
        "    new_x = new_x.reshape([-1, n_fea * time_window])\n",
        "    new_y = np.array(new_y)\n",
        "    new_y.shape = [new_y.shape[0], 1]\n",
        "    data = np.hstack((new_x, new_y))\n",
        "    data = np.vstack((data, data[-1]))  # add the last sample again, to make the sample number round\n",
        "    return data\n",
        "\n",
        "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
        "print('After segmentation, the shape of the data:', data_seg.shape)\n",
        "\n",
        "# split training and test data\n",
        "no_longfeature = no_feature*segment_length\n",
        "data_seg_feature = data_seg[:, :no_longfeature]\n",
        "data_seg_label = data_seg[:, no_longfeature:no_longfeature+1]\n",
        "train_feature, test_feature, train_label, test_label = train_test_split(data_seg_feature, data_seg_label,test_size=0.2, shuffle=True)\n",
        "\n",
        "# normalization\n",
        "# before normalize reshape data back to raw data shape\n",
        "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
        "test_feature_2d = test_feature.reshape([-1, no_feature])\n",
        "\n",
        "scaler1 = StandardScaler().fit(train_feature_2d)\n",
        "train_fea_norm1 = scaler1.transform(train_feature_2d) # normalize the training data\n",
        "test_fea_norm1 = scaler1.transform(test_feature_2d) # normalize the test data\n",
        "print('After normalization, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter normalization, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "# after normalization, reshape data to 3d in order to feed in to LSTM\n",
        "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "test_fea_norm1 = test_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "print('After reshape, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter reshape, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "BATCH_size = test_fea_norm1.shape[0] # use test_data as batch size\n",
        "\n",
        "# feed data into dataloader\n",
        "train_fea_norm1 = torch.tensor(train_fea_norm1)\n",
        "train_fea_norm1 = torch.unsqueeze(train_fea_norm1, dim=1).type('torch.FloatTensor').to(device)\n",
        "# print(train_fea_norm1.shape)\n",
        "train_label = torch.tensor(train_label.flatten()).to(device)\n",
        "train_data = Data.TensorDataset(train_fea_norm1, train_label)\n",
        "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_size, shuffle=False)\n",
        "\n",
        "test_fea_norm1 = torch.tensor(test_fea_norm1)\n",
        "test_fea_norm1 = torch.unsqueeze(test_fea_norm1, dim=1).type('torch.FloatTensor').to(device)\n",
        "test_label = torch.tensor(test_label.flatten()).to(device)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=16,\n",
        "                kernel_size=(2,4),\n",
        "                stride=1,\n",
        "                padding= (1,2)  #([1,2]-1)/2,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2,4))\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, (2,2), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2))\n",
        "        )\n",
        "        self.fc = nn.Linear(4*8*32, 128)  # 64*2*4\n",
        "        self.out = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = F.dropout(x, 0.2)\n",
        "\n",
        "        output = self.out(x)\n",
        "        return output, x\n",
        "\n",
        "cnn = CNN()\n",
        "cnn.to(device)\n",
        "print(cnn)\n",
        "\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR, weight_decay=l2)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "best_acc = []\n",
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "\n",
        "        output = cnn(train_x)[0]  # CNN output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = cnn(test_fea_norm1)[0]  # CNN output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())  # .cpu() can be removed if your device is cpu.\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "\n",
        "        print('Epoch: ', epoch,  '|train loss: %.4f' % loss.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)\n",
        "\n",
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "print(classification_report(test_label.data.cpu().numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SySStNrQ-KOv",
        "outputId": "91cea89a-91cc-4f3f-e625-7b348aef1b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are using cpu now.\n",
            "After segmentation, the shape of the data: (2440, 1025)\n",
            "After normalization, the shape of training feature: (31232, 64) \n",
            "After normalization, the shape of test feature: (7808, 64)\n",
            "After reshape, the shape of training feature: (1952, 16, 64) \n",
            "After reshape, the shape of test feature: (488, 16, 64)\n",
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(2, 4), stride=(1, 1), padding=(1, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 4), stride=(2, 4), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=1024, out_features=128, bias=True)\n",
            "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n",
            "Epoch:  0 |train loss: 0.7355  train ACC: 0.4795 | test loss: 0.6728 test ACC: 0.5717 | AUC: 0.6772\n",
            "Epoch:  10 |train loss: 0.2029  train ACC: 0.9303 | test loss: 0.3494 test ACC: 0.8709 | AUC: 0.9469\n",
            "Epoch:  20 |train loss: 0.1693  train ACC: 0.9365 | test loss: 0.2348 test ACC: 0.8996 | AUC: 0.9697\n",
            "Epoch:  30 |train loss: 0.1557  train ACC: 0.9447 | test loss: 0.1904 test ACC: 0.9201 | AUC: 0.9797\n",
            "Epoch:  40 |train loss: 0.0980  train ACC: 0.9693 | test loss: 0.1751 test ACC: 0.9160 | AUC: 0.9839\n",
            "Epoch:  50 |train loss: 0.1177  train ACC: 0.9549 | test loss: 0.1809 test ACC: 0.9242 | AUC: 0.9886\n",
            "Epoch:  60 |train loss: 0.0769  train ACC: 0.9836 | test loss: 0.1710 test ACC: 0.9262 | AUC: 0.9869\n",
            "Epoch:  70 |train loss: 0.0963  train ACC: 0.9672 | test loss: 0.1318 test ACC: 0.9426 | AUC: 0.9892\n",
            "Epoch:  80 |train loss: 0.1006  train ACC: 0.9652 | test loss: 0.1306 test ACC: 0.9488 | AUC: 0.9906\n",
            "Epoch:  90 |train loss: 0.0645  train ACC: 0.9877 | test loss: 0.1630 test ACC: 0.9303 | AUC: 0.9895\n",
            "Epoch:  100 |train loss: 0.0669  train ACC: 0.9795 | test loss: 0.1630 test ACC: 0.9324 | AUC: 0.9889\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.91      0.93       250\n",
            "         1.0       0.91      0.96      0.93       238\n",
            "\n",
            "    accuracy                           0.93       488\n",
            "   macro avg       0.93      0.93      0.93       488\n",
            "weighted avg       0.93      0.93      0.93       488\n",
            "\n",
            "BEST TEST ACC: 0.9487704918032787, AUC: 0.9906050420168067\n",
            "Total Running Time: 128.39 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "trying to change the layers of the CNN"
      ],
      "metadata": {
        "id": "lPt0h2r-ACAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# # load dataset\n",
        "# dataset_1 = np.load('1.npy')\n",
        "# print('dataset_1 shape:', dataset_1.shape)\n",
        "\n",
        "# check if a GPU is available\n",
        "with_gpu = torch.cuda.is_available()\n",
        "if with_gpu:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print('We are using %s now.' %device)\n",
        "\n",
        "# remove instance with label==10 (rest)\n",
        "removed_label = [2,3,4,5,6,7,8,9,10]  #2,3,4,5,\n",
        "for ll in removed_label:\n",
        "    id = dataset_1[:, -1]!=ll\n",
        "    dataset_1 = dataset_1[id]\n",
        "\n",
        "def one_hot(y_):\n",
        "    # Function to encode output labels from number indexes\n",
        "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    y_ = [int(xx) for xx in y_]\n",
        "    n_values = np.max(y_) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
        "\n",
        "# data segmentation\n",
        "n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
        "no_feature = 64  # the number of the features\n",
        "segment_length = 16  # selected time window; 16=160*0.1\n",
        "LR = 0.005  # learning rate\n",
        "EPOCH = 101\n",
        "n_hidden = 128  # number of neurons in hidden layer\n",
        "l2 = 0.01  # the coefficient of l2-norm regularization\n",
        "\n",
        "def extract(input, n_classes, n_fea, time_window, moving):\n",
        "    xx = input[:, :n_fea]\n",
        "    yy = input[:, n_fea:n_fea + 1]\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    number = int((xx.shape[0] / moving) - 1)\n",
        "    for i in range(number):\n",
        "        ave_y = np.average(yy[int(i * moving):int(i * moving + time_window)])\n",
        "        if ave_y in range(n_classes + 1):\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(ave_y)\n",
        "        else:\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(0)\n",
        "\n",
        "    new_x = np.array(new_x)\n",
        "    new_x = new_x.reshape([-1, n_fea * time_window])\n",
        "    new_y = np.array(new_y)\n",
        "    new_y.shape = [new_y.shape[0], 1]\n",
        "    data = np.hstack((new_x, new_y))\n",
        "    data = np.vstack((data, data[-1]))  # add the last sample again, to make the sample number round\n",
        "    return data\n",
        "\n",
        "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
        "print('After segmentation, the shape of the data:', data_seg.shape)\n",
        "\n",
        "# split training and test data\n",
        "no_longfeature = no_feature*segment_length\n",
        "data_seg_feature = data_seg[:, :no_longfeature]\n",
        "data_seg_label = data_seg[:, no_longfeature:no_longfeature+1]\n",
        "train_feature, test_feature, train_label, test_label = train_test_split(data_seg_feature, data_seg_label,test_size=0.2, shuffle=True)\n",
        "\n",
        "# normalization\n",
        "# before normalize reshape data back to raw data shape\n",
        "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
        "test_feature_2d = test_feature.reshape([-1, no_feature])\n",
        "\n",
        "scaler1 = StandardScaler().fit(train_feature_2d)\n",
        "train_fea_norm1 = scaler1.transform(train_feature_2d) # normalize the training data\n",
        "test_fea_norm1 = scaler1.transform(test_feature_2d) # normalize the test data\n",
        "print('After normalization, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter normalization, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "# after normalization, reshape data to 3d in order to feed in to LSTM\n",
        "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "test_fea_norm1 = test_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "print('After reshape, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter reshape, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "BATCH_size = test_fea_norm1.shape[0] # use test_data as batch size\n",
        "\n",
        "# feed data into dataloader\n",
        "train_fea_norm1 = torch.tensor(train_fea_norm1)\n",
        "train_fea_norm1 = torch.unsqueeze(train_fea_norm1, dim=1).type('torch.FloatTensor').to(device)\n",
        "# print(train_fea_norm1.shape)\n",
        "train_label = torch.tensor(train_label.flatten()).to(device)\n",
        "train_data = Data.TensorDataset(train_fea_norm1, train_label)\n",
        "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_size, shuffle=False)\n",
        "\n",
        "test_fea_norm1 = torch.tensor(test_fea_norm1)\n",
        "test_fea_norm1 = torch.unsqueeze(test_fea_norm1, dim=1).type('torch.FloatTensor').to(device)\n",
        "test_label = torch.tensor(test_label.flatten()).to(device)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        #add more layers to CNN see if more accurate change act layer\n",
        "        self.conv1 = nn.Sequential(\n",
        "          nn.Conv2d(1, 16, kernel_size=(3,3), stride=1, padding=1),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.LeakyReLU(),\n",
        "          nn.MaxPool2d((2,2))\n",
        "      )\n",
        "#comment origional\n",
        "        # self.conv1 = nn.Sequential(\n",
        "        #     nn.Conv2d(\n",
        "        #         in_channels=1,\n",
        "        #         out_channels=16,\n",
        "        #         kernel_size=(2,4),\n",
        "        #         stride=1,\n",
        "        #         padding= (1,2)  #([1,2]-1)/2,\n",
        "        #     ),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d((2,4))\n",
        "        # )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, (2,2), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2))\n",
        "        )\n",
        "        self.fc = nn.Linear(32 * 4 * 16, 128)  # Replace 4*8*32 with calculated dimensions\n",
        "\n",
        "        # self.fc = nn.Linear(4*8*32, 128)  # 64*2*4\n",
        "        self.out = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = F.dropout(x, 0.2)\n",
        "\n",
        "        output = self.out(x)\n",
        "        return output, x\n",
        "\n",
        "cnn = CNN()\n",
        "cnn.to(device)\n",
        "print(cnn)\n",
        "\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR, weight_decay=l2)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "best_acc = []\n",
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "\n",
        "        output = cnn(train_x)[0]  # CNN output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = cnn(test_fea_norm1)[0]  # CNN output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())  # .cpu() can be removed if your device is cpu.\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "\n",
        "        print('Epoch: ', epoch,  '|train loss: %.4f' % loss.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)\n",
        "\n",
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "print(classification_report(test_label.data.cpu().numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9cc7e5-164f-4667-c343-d2857b34d5f7",
        "id": "eso9DJVG_lY-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are using cpu now.\n",
            "After segmentation, the shape of the data: (2440, 1025)\n",
            "After normalization, the shape of training feature: (31232, 64) \n",
            "After normalization, the shape of test feature: (7808, 64)\n",
            "After reshape, the shape of training feature: (1952, 16, 64) \n",
            "After reshape, the shape of test feature: (488, 16, 64)\n",
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01)\n",
            "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n",
            "Epoch:  0 |train loss: 0.9166  train ACC: 0.5164 | test loss: 0.6842 test ACC: 0.5512 | AUC: 0.6007\n",
            "Epoch:  10 |train loss: 0.2784  train ACC: 0.8893 | test loss: 0.2546 test ACC: 0.9160 | AUC: 0.9616\n",
            "Epoch:  20 |train loss: 0.1633  train ACC: 0.9242 | test loss: 0.2707 test ACC: 0.8832 | AUC: 0.9715\n",
            "Epoch:  30 |train loss: 0.1280  train ACC: 0.9488 | test loss: 0.1730 test ACC: 0.9385 | AUC: 0.9793\n",
            "Epoch:  40 |train loss: 0.0698  train ACC: 0.9816 | test loss: 0.1519 test ACC: 0.9488 | AUC: 0.9844\n",
            "Epoch:  50 |train loss: 0.0600  train ACC: 0.9877 | test loss: 0.1451 test ACC: 0.9488 | AUC: 0.9855\n",
            "Epoch:  60 |train loss: 0.4419  train ACC: 0.8340 | test loss: 0.1897 test ACC: 0.9201 | AUC: 0.9812\n",
            "Epoch:  70 |train loss: 0.0479  train ACC: 0.9918 | test loss: 0.1533 test ACC: 0.9488 | AUC: 0.9829\n",
            "Epoch:  80 |train loss: 0.0512  train ACC: 0.9857 | test loss: 0.1262 test ACC: 0.9508 | AUC: 0.9886\n",
            "Epoch:  90 |train loss: 0.0735  train ACC: 0.9693 | test loss: 0.1291 test ACC: 0.9529 | AUC: 0.9889\n",
            "Epoch:  100 |train loss: 0.0369  train ACC: 0.9939 | test loss: 0.1228 test ACC: 0.9611 | AUC: 0.9897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.99      0.96       248\n",
            "         1.0       0.99      0.93      0.96       240\n",
            "\n",
            "    accuracy                           0.96       488\n",
            "   macro avg       0.96      0.96      0.96       488\n",
            "weighted avg       0.96      0.96      0.96       488\n",
            "\n",
            "BEST TEST ACC: 0.9610655737704918, AUC: 0.9897009408602151\n",
            "Total Running Time: 161.25 seconds\n"
          ]
        }
      ]
    }
  ]
}