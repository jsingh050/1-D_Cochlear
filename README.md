# 1-D_Cochlear
1-dimensional cochlear model
In this project, I created a neuromorphic event-based audio sensor that models a 1D cochlea using a microphone. When audio is spoken into the microphone, the sensor processes the audio signals (in this case, spoken digits) by applying Fast Fourier Transform (FFT), breaking down the audio into frequency bands, and generating spike-based events based on power thresholds in each band.

The project mimics the human cochlea, which converts sound into electrical signals by detecting frequency components.

Building a neuromorphic 1D cochlea is important because it simulates how the human ear processes sound in real-time, enabling efficient, low-power signal processing similar to biological systems. This approach is especially valuable for developing auditory prosthetics (e.g., cochlear implants) and low-power audio processing systems for speech recognition and other applications, as it captures key auditory features while minimizing computational and power demands.
